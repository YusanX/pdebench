"""
PDEBench Case-Driven Testing Framework (SWE-bench Style)

æ ‡å‡†åŒ–çš„æµ‹è¯•æ¥å£ï¼Œæ¯ä¸ªcaseä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•è„šæœ¬ã€‚
åŒ…å«æ‰€æœ‰ PDE ç±»å‹çš„æµ‹è¯•åŸºç±»ã€‚
"""

import json
import sys
import time
from pathlib import Path
from typing import Dict, Any, Optional, Literal
from abc import ABC, abstractmethod
import numpy as np

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from pdebench.sandbox.executor import execute_agent_script
from pdebench.oracle import generate


class BaseCaseTest(ABC):
    """
    æ¡ˆä¾‹æµ‹è¯•åŸºç±» - æ¯ä¸ªcaseç»§æ‰¿æ­¤ç±»å®ç°ç‹¬ç«‹çš„æµ‹è¯•é€»è¾‘
    
    æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
    1. å•ä¸€æŒ‡æ ‡ä¼˜åŒ–ï¼šæ¯ä¸ªteståªä¼˜åŒ–ä¸€ä¸ªç›®æ ‡ï¼ˆæ—¶é—´æˆ–ç²¾åº¦ï¼‰ï¼Œå›ºå®šå…¶ä»–å‚æ•°
    2. ç‹¬ç«‹æ€§ï¼šæ¯ä¸ªcaseæœ‰ç‹¬ç«‹çš„æµ‹è¯•è„šæœ¬ï¼Œäº’ä¸å¹²æ‰°
    3. æ ‡å‡†åŒ–ï¼šæ‰€æœ‰åŒç±»PDEéµå¾ªç›¸åŒçš„APIæ¥å£
    """
    
    def __init__(self, case_dir: Path, agent_dir: Optional[Path] = None):
        self.case_dir = Path(case_dir)
        self.config = self._load_config()
        self.case_id = self.config['id']
        
        # å¦‚æœæä¾›äº†agent_dirï¼Œç»“æœä¿å­˜åˆ°agentç›®å½•ä¸‹ï¼›å¦åˆ™ä¿å­˜åˆ°caseç›®å½•ä¸‹
        if agent_dir:
            self.output_dir = agent_dir / self.case_id / 'test_output'
        else:
            self.output_dir = self.case_dir / 'test_output'
        
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.agent_output_dir = self.output_dir / 'agent_output'
        self.oracle_output_dir = self.output_dir / 'oracle_output'
        self.agent_output_dir.mkdir(parents=True, exist_ok=True)
        self.oracle_output_dir.mkdir(parents=True, exist_ok=True)
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½caseé…ç½®"""
        config_file = self.case_dir / 'config.json'
        if not config_file.exists():
            raise FileNotFoundError(f"Config not found: {config_file}")
        
        with open(config_file) as f:
            return json.load(f)
    
    @abstractmethod
    def get_pde_type(self) -> str:
        """è¿”å›PDEç±»å‹"""
        pass
    
    def run_test(
        self, 
        agent_script: Path,
        test_mode: Literal['fix_accuracy', 'fix_time'],
        timeout_sec: int = 300
    ) -> Dict[str, Any]:
        """
        è¿è¡Œæµ‹è¯•
        
        Args:
            agent_script: Agentç”Ÿæˆçš„æ±‚è§£å™¨è„šæœ¬
            test_mode: æµ‹è¯•æ¨¡å¼
                - 'fix_accuracy': å›ºå®šç²¾åº¦ç›®æ ‡ï¼Œä¼˜åŒ–è¿è¡Œæ—¶é—´
                - 'fix_time': å›ºå®šæ—¶é—´é¢„ç®—ï¼Œä¼˜åŒ–ç²¾åº¦
            timeout_sec: è¶…æ—¶æ—¶é—´
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        print(f"\n{'='*80}")
        print(f"ğŸ§ª Case: {self.case_id}")
        print(f"ğŸ“‹ Test Mode: {test_mode}")
        print(f"{'='*80}\n")
        
        # è·å–æµ‹è¯•å‚æ•°
        test_params = self._get_test_params(test_mode)
        
        # ç”ŸæˆOracleå‚è€ƒè§£
        print("ğŸ”® Generating oracle reference solution...")
        oracle_config = self.config['oracle_config']
        generate(oracle_config, self.oracle_output_dir)
        print(f"   âœ… Oracle saved to {self.oracle_output_dir}")
        
        # æ‰§è¡ŒAgentè„šæœ¬
        print(f"\nğŸ¤– Executing agent script: {agent_script.name}")
        print(f"   Parameters: {test_params}")
        
        agent_result = execute_agent_script(
            script_path=agent_script,
            outdir=self.agent_output_dir,
            timeout_sec=timeout_sec,
            **test_params
        )
        
        if not agent_result.success:
            result = {
                'case_id': self.case_id,
                'test_mode': test_mode,
                'status': 'FAILED',
                'error': agent_result.error_message,
                'score': 0.0,
                'tier_levels': {'passed': [], 'total': 3, 'level_details': {f'level_{i}': False for i in [1, 2, 3]}}
            }
            # ä¿å­˜ç»“æœ
            result_file = self.output_dir / f'result_{test_mode}.json'
            with open(result_file, 'w') as f:
                json.dump(result, f, indent=2)
            self._print_result(result)
            return result
        
        print(f"   âœ… Agent execution completed in {agent_result.t_agent_run:.3f}s")
        
        # è®¡ç®—è¯¯å·®
        error = self._compute_error()
        
        if np.isnan(error):
            result = {
                'case_id': self.case_id,
                'test_mode': test_mode,
                'status': 'FAILED',
                'error': 'Error computation returned NaN',
                'score': 0.0,
                'tier_levels': {'passed': [], 'total': 3, 'level_details': {f'level_{i}': False for i in [1, 2, 3]}}
            }
            # ä¿å­˜ç»“æœ
            result_file = self.output_dir / f'result_{test_mode}.json'
            with open(result_file, 'w') as f:
                json.dump(result, f, indent=2)
            self._print_result(result)
            return result
        
        print(f"   ğŸ“Š Relative L2 Error: {error:.6e}")
        
        # æ ¹æ®æµ‹è¯•æ¨¡å¼è®¡ç®—å¾—åˆ†
        score = self._compute_score(
            mode=test_mode,
            runtime=agent_result.t_agent_run,
            error=error,
            target_error=self.config['evaluation_config']['target_error'],
            time_budget=self.config['evaluation_config'].get('time_budget', 60.0)
        )
        
        # è®¡ç®—é€šè¿‡äº†å“ªäº› tier levels
        passed_levels = self._check_tier_levels(
            mode=test_mode,
            runtime=agent_result.t_agent_run,
            error=error
        )
        
        result = {
            'case_id': self.case_id,
            'test_mode': test_mode,
            'status': 'PASSED' if score > 0 else 'FAILED',
            'runtime_sec': agent_result.t_agent_run,
            'error': float(error),
            'target_error': self.config['evaluation_config']['target_error'],
            'score': score,
            'test_params': test_params,
            'tier_levels': passed_levels  # æ–°å¢ï¼šé€šè¿‡çš„ç­‰çº§
        }
        
        # è®¡ç®—ä¸“ç”¨æŒ‡æ ‡ï¼ˆå¦‚æœå­ç±»å®ç°äº†ï¼‰
        try:
            specialized_metrics = self._compute_specialized_metrics(result)
            if specialized_metrics:
                result['specialized_metrics'] = specialized_metrics
        except NotImplementedError:
            pass  # åŸºç±»ä¸å¼ºåˆ¶è¦æ±‚å®ç°
        
        # ä¿å­˜ç»“æœ
        result_file = self.output_dir / f'result_{test_mode}.json'
        with open(result_file, 'w') as f:
            json.dump(result, f, indent=2)
        
        self._print_result(result)
        
        return result
    
    @abstractmethod
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        è·å–æµ‹è¯•å‚æ•°ï¼ˆå­ç±»å®ç°ï¼‰
        
        æ ¹æ®æµ‹è¯•æ¨¡å¼è¿”å›ä¸åŒçš„å‚æ•°ï¼š
        - fix_accuracyæ¨¡å¼ï¼šä½¿ç”¨æ¨èçš„é«˜ç²¾åº¦é…ç½®
        - fix_timeæ¨¡å¼ï¼šä½¿ç”¨æ¨èçš„å¿«é€Ÿé…ç½®
        """
        pass
    
    def _compute_error(self) -> float:
        """è®¡ç®—è¯¯å·®ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–çš„éªŒè¯å™¨ï¼‰"""
        from pdebench.evaluation.validator import validate_solution
        
        validation_result = validate_solution(
            agent_outdir=self.agent_output_dir,
            oracle_outdir=self.oracle_output_dir,
            evaluation_config=self.config['evaluation_config'],
            oracle_config=self.config['oracle_config']
        )
        
        return validation_result.rel_L2_error
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®— PDE ç±»å‹ä¸“ç”¨æŒ‡æ ‡ï¼ˆå­ç±»å¯é€‰å®ç°ï¼‰
        
        Returns:
            ä¸“ç”¨æŒ‡æ ‡å­—å…¸ï¼Œå¦‚ï¼š
            - åŒæ›²ï¼šovershoot, conservation_error
            - Stokes: divergence_error
            - éçº¿æ€§ï¼šnewton_iterations
        """
        raise NotImplementedError("Subclass should implement if specialized metrics are needed")
    
    def _read_solver_info(self) -> Dict[str, Any]:
        """
        è¯»å–æ±‚è§£å™¨ä¿¡æ¯ï¼ˆä» meta.jsonï¼‰
        
        Returns:
            æ±‚è§£å™¨ä¿¡æ¯å­—å…¸ï¼Œå¯èƒ½åŒ…å«ï¼š
            - linear_solver_type: çº¿æ€§æ±‚è§£å™¨ç±»å‹ (CG, GMRES, etc.)
            - preconditioner_type: é¢„æ¡ä»¶å™¨ç±»å‹ (AMG, ILU, etc.)
            - linear_iterations_mean: å¹³å‡çº¿æ€§è¿­ä»£æ¬¡æ•°
            - linear_iterations_max: æœ€å¤§çº¿æ€§è¿­ä»£æ¬¡æ•°
            - nonlinear_iterations: éçº¿æ€§è¿­ä»£æ¬¡æ•°ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        """
        solver_info = {}
        
        try:
            meta_file = self.agent_output_dir / 'meta.json'
            if not meta_file.exists():
                return solver_info
            
            with open(meta_file) as f:
                meta = json.load(f)
            
            # è¯»å–çº¿æ€§æ±‚è§£å™¨ä¿¡æ¯
            if 'linear_solver' in meta:
                ls = meta['linear_solver']
                if isinstance(ls, dict):
                    solver_info['linear_solver_type'] = ls.get('type', 'unknown')
                    solver_info['preconditioner_type'] = ls.get('preconditioner', 'none')
                    
                    # è¿­ä»£æ¬¡æ•°
                    if 'iterations' in ls:
                        iters = ls['iterations']
                        if isinstance(iters, list):
                            solver_info['linear_iterations_mean'] = float(np.mean(iters))
                            solver_info['linear_iterations_max'] = int(np.max(iters))
                            solver_info['linear_iterations_total'] = int(np.sum(iters))
                        else:
                            solver_info['linear_iterations'] = iters
            
            # è¯»å–éçº¿æ€§æ±‚è§£å™¨ä¿¡æ¯
            if 'nonlinear_solver' in meta:
                ns = meta['nonlinear_solver']
                if isinstance(ns, dict):
                    solver_info['nonlinear_solver_type'] = ns.get('type', 'unknown')
                    
                    if 'iterations' in ns:
                        iters = ns['iterations']
                        if isinstance(iters, list):
                            solver_info['nonlinear_iterations_mean'] = float(np.mean(iters))
                            solver_info['nonlinear_iterations_max'] = int(np.max(iters))
                        else:
                            solver_info['nonlinear_iterations'] = iters
            
            # è¯»å–ç¦»æ•£åŒ–æ–¹æ³•
            if 'discretization_method' in meta:
                solver_info['discretization_method'] = meta['discretization_method']
            
            # è¯»å–æ—¶é—´ç§¯åˆ†æ–¹æ³•ï¼ˆå¦‚æœæ˜¯ç¬æ€é—®é¢˜ï¼‰
            if 'time_integrator' in meta:
                solver_info['time_integrator'] = meta['time_integrator']
            
        except Exception as e:
            solver_info['read_error'] = f"Failed to read solver info: {str(e)}"
        
        return solver_info
    
    def _compute_score(
        self,
        mode: str,
        runtime: float,
        error: float,
        target_error: float,
        time_budget: float
    ) -> float:
        """
        è®¡ç®—å¾—åˆ†ï¼ˆ0-100ï¼‰
        
        fix_accuracyæ¨¡å¼ï¼šå›ºå®šç²¾åº¦ï¼Œæ¯”é€Ÿåº¦
        - å¿…é¡»è¾¾åˆ°target_erroræ‰æœ‰åˆ†
        - å¾—åˆ† = 100 * (time_budget / runtime)ï¼Œè¶Šå¿«å¾—åˆ†è¶Šé«˜
        
        fix_timeæ¨¡å¼ï¼šå›ºå®šæ—¶é—´ï¼Œæ¯”ç²¾åº¦
        - å¿…é¡»åœ¨time_budgetå†…å®Œæˆæ‰æœ‰åˆ†
        - å¾—åˆ† = 100 * (1 - min(error/target_error, 1.0))ï¼Œè¯¯å·®è¶Šå°å¾—åˆ†è¶Šé«˜
        """
        if mode == 'fix_accuracy':
            # å›ºå®šç²¾åº¦æ¨¡å¼ï¼šå¿…é¡»è¾¾åˆ°ç²¾åº¦è¦æ±‚
            if error > target_error:
                print(f"   âŒ Failed: error {error:.2e} > target {target_error:.2e}")
                return 0.0
            
            # è®¡ç®—é€Ÿåº¦å¾—åˆ†ï¼šè¶Šå¿«è¶Šå¥½
            if runtime > time_budget:
                score = 50.0 * (time_budget / runtime)  # è¶…æ—¶ä½†æ­£ç¡®ï¼Œç»™éƒ¨åˆ†åˆ†
            else:
                score = 100.0 * (time_budget / max(runtime, 0.1))  # å¿«äºé¢„ç®—ï¼Œé«˜åˆ†
                score = min(score, 100.0)
            
            print(f"   âœ… Passed: Accuracy target met in {runtime:.3f}s (budget: {time_budget:.1f}s)")
            print(f"   ğŸ¯ Score: {score:.1f}/100")
            return score
        
        elif mode == 'fix_time':
            # å›ºå®šæ—¶é—´æ¨¡å¼ï¼šå¿…é¡»åœ¨æ—¶é—´é¢„ç®—å†…
            if runtime > time_budget:
                print(f"   âŒ Failed: runtime {runtime:.3f}s > budget {time_budget:.1f}s")
                return 0.0
            
            # è®¡ç®—ç²¾åº¦å¾—åˆ†ï¼šè¯¯å·®è¶Šå°è¶Šå¥½
            error_ratio = error / target_error
            if error_ratio >= 1.0:
                score = 10.0  # è¶…è¿‡ç›®æ ‡è¯¯å·®ï¼Œç»™åŸºç¡€åˆ†
            else:
                # è¯¯å·®è¶Šå°ï¼Œå¾—åˆ†è¶Šé«˜ï¼ˆéçº¿æ€§ï¼‰
                score = 100.0 * (1.0 - error_ratio)
            
            print(f"   âœ… Passed: Achieved error {error:.2e} within {runtime:.3f}s")
            print(f"   ğŸ¯ Score: {score:.1f}/100")
            return score
        
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _check_tier_levels(self, mode: str, runtime: float, error: float) -> Dict[str, Any]:
        """æ£€æŸ¥é€šè¿‡äº†å“ªäº› tier levels"""
        if 'tiers' not in self.config:
            return {'passed': [], 'total': 0}
        
        tiers = self.config['tiers']
        passed = []
        
        if mode == 'fix_accuracy':
            # é€Ÿåº¦æ¦œï¼šæ£€æŸ¥åœ¨ä¸åŒæ—¶é—´é™åˆ¶ä¸‹èƒ½å¦è¾¾åˆ°ä¸­ç­‰ç²¾åº¦
            target_error = tiers['accuracy']['level_2']['target_error']
            if error <= target_error:
                # è¾¾åˆ°ç²¾åº¦è¦æ±‚ï¼Œæ£€æŸ¥é€Ÿåº¦ç­‰çº§
                if runtime <= tiers['speed']['fast']['time_budget']:
                    passed = [1, 2, 3]  # é€šè¿‡æ‰€æœ‰ç­‰çº§
                elif runtime <= tiers['speed']['medium']['time_budget']:
                    passed = [1, 2]  # é€šè¿‡ L1, L2
                elif runtime <= tiers['speed']['slow']['time_budget']:
                    passed = [1]  # åªé€šè¿‡ L1
        
        elif mode == 'fix_time':
            # ç²¾åº¦æ¦œï¼šæ£€æŸ¥åœ¨æ—¶é—´é™åˆ¶å†…èƒ½è¾¾åˆ°å“ªä¸ªç²¾åº¦ç­‰çº§
            time_budget = tiers['speed']['medium']['time_budget']
            if runtime <= time_budget:
                if error <= tiers['accuracy']['level_3']['target_error']:
                    passed = [1, 2, 3]  # é«˜ç²¾åº¦
                elif error <= tiers['accuracy']['level_2']['target_error']:
                    passed = [1, 2]  # ä¸­ç²¾åº¦
                elif error <= tiers['accuracy']['level_1']['target_error']:
                    passed = [1]  # ä½ç²¾åº¦
        
        return {
            'passed': passed,
            'total': 3,
            'level_details': {
                f'level_{i}': (i in passed) for i in [1, 2, 3]
            }
        }
    
    def _print_result(self, result: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print(f"\n{'â”€'*80}")
        print(f"ğŸ“Š Test Result: {result['case_id']}")
        print(f"{'â”€'*80}")
        print(f"Status: {result['status']}")
        
        # åªåœ¨å­—æ®µå­˜åœ¨æ—¶æ‰“å°
        if 'runtime_sec' in result:
            print(f"Runtime: {result['runtime_sec']:.3f}s")
        if 'error' in result and isinstance(result['error'], (int, float)):
            print(f"Error: {result['error']:.6e}")
        elif 'error' in result:
            print(f"Error: {result['error']}")
        if 'target_error' in result:
            print(f"Target Error: {result['target_error']:.6e}")
        print(f"Score: {result.get('score', 0.0):.1f}/100")
        
        # æ‰“å° tier levels
        if 'tier_levels' in result:
            levels = result['tier_levels']
            passed = levels['passed']
            total = levels['total']
            print(f"Tier Levels: {len(passed)}/{total} passed {passed}")
        
        # æ‰“å°ä¸“ç”¨æŒ‡æ ‡
        if 'specialized_metrics' in result:
            print(f"Specialized Metrics: {result['specialized_metrics']}")
        
        print(f"{'â”€'*80}\n")


# ============================================================================
# åŸºç¡€ PDE ç±»å‹æµ‹è¯•ç±»
# ============================================================================

class EllipticCaseTest(BaseCaseTest):
    """
    æ¤­åœ†å‹æ–¹ç¨‹æµ‹è¯•åŸºç±» (Standard Elliptic Test)
    
    ä¸»è¦ç”¨äºæ³Šæ¾æ–¹ç¨‹ (Poisson) ç­‰æ ‡å‡†æ¤­åœ†å‹é—®é¢˜ã€‚
    """
    
    def get_pde_type(self) -> str:
        return 'elliptic'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        æ³Šæ¾æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - fix_accuracy: é«˜ç²¾åº¦é…ç½® (N=128, P=2)
        - fix_time: å¿«é€Ÿé…ç½® (N=32, P=1)
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 128,
                'degree': 2
            }
        elif mode == 'fix_time':
            return {
                'resolution': 32,
                'degree': 1
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—æ¤­åœ†å‹æ–¹ç¨‹ä¸“ç”¨æŒ‡æ ‡ï¼š
        - efficiency_dof_per_sec: æ±‚è§£æ•ˆç‡ DOF/s
        - dof: è‡ªç”±åº¦æ•°é‡
        - solver_iterations: çº¿æ€§æ±‚è§£å™¨è¿­ä»£æ¬¡æ•°
        - convergence_rate_estimate: æ”¶æ•›é˜¶ä¼°è®¡ p_est = log(E1/E2)/log(h1/h2)
        - condition_number_estimate: æ¡ä»¶æ•°ä¼°è®¡ï¼ˆä»è¿­ä»£æ¬¡æ•°æ¨æ–­ï¼‰
        """
        metrics = {}
        
        try:
            # 1. è®¡ç®— DOFï¼ˆæ›´å‡†ç¡®çš„ä¼°è®¡ï¼‰
            resolution = result.get('test_params', {}).get('resolution', 0)
            degree = result.get('test_params', {}).get('degree', 1)
            
            # 2D ä¸‰è§’å½¢ç½‘æ ¼ï¼šDOF â‰ˆ (N+1)^2 for P1, æ›´å¤æ‚å¯¹äº P2+
            # ç®€åŒ–ä¼°è®¡ï¼šDOF â‰ˆ N^2 * (degree+1)*(degree+2)/2 (2D ä¸‰è§’å½¢ä¸Šçš„ P^k å…ƒ)
            if degree == 1:
                dof = resolution ** 2
            elif degree == 2:
                dof = (2 * resolution + 1) ** 2  # P2 å¤§çº¦æœ‰ (2N+1)^2 ä¸ªèŠ‚ç‚¹
            else:
                dof = resolution ** 2 * degree ** 2  # ç²—ç•¥ä¼°è®¡
            
            metrics['dof'] = int(dof)
            metrics['resolution'] = int(resolution)
            metrics['degree'] = int(degree)
            
            # 2. è®¡ç®—æ•ˆç‡ DOF/s
            runtime = result.get('runtime_sec', 0)
            if runtime > 0:
                efficiency = dof / runtime
                metrics['efficiency_dof_per_sec'] = float(efficiency)
            
            # 3. è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
                
                # æ¡ä»¶æ•°ä¼°è®¡ï¼ˆä» CG è¿­ä»£æ¬¡æ•°æ¨æ–­ï¼‰
                if 'linear_iterations_mean' in solver_info:
                    iters = solver_info['linear_iterations_mean']
                    # å¯¹äº SPD ç³»ç»Ÿï¼ŒCG è¿­ä»£æ¬¡æ•° ~ sqrt(Îº)
                    if iters > 0:
                        kappa_estimate = iters ** 2
                        metrics['condition_number_estimate'] = float(kappa_estimate)
            
            # 4. æ”¶æ•›é˜¶ä¼°è®¡ï¼ˆéœ€è¦å¤šåˆ†è¾¨ç‡æ•°æ®ï¼‰
            # å¦‚æœæœ‰å†å²è¯¯å·®æ•°æ®ï¼Œå¯ä»¥ä¼°è®¡æ”¶æ•›é˜¶
            # è¿™é‡Œæš‚æ—¶ä¸å®ç°ï¼Œéœ€è¦å­˜å‚¨å¤šæ¬¡è¿è¡Œçš„ç»“æœ
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics


class ParabolicCaseTest(BaseCaseTest):
    """
    æŠ›ç‰©å‹æ–¹ç¨‹æµ‹è¯•åŸºç±» (Standard Parabolic Test)
    
    ä¸»è¦ç”¨äºçƒ­æ–¹ç¨‹ (Heat Equation) ç­‰æ ‡å‡†æŠ›ç‰©å‹é—®é¢˜ã€‚
    """
    
    def get_pde_type(self) -> str:
        return 'parabolic'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        çƒ­æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - fix_accuracy: é«˜ç²¾åº¦é…ç½® (N=128, P=2, dt=0.001)
        - fix_time: å¿«é€Ÿé…ç½® (N=32, P=1, dt=0.01)
        """
        oracle_time_config = self.config['oracle_config']['pde']['time']
        dt_oracle = oracle_time_config['dt']
        
        if mode == 'fix_accuracy':
            return {
                'resolution': 128,
                'degree': 2,
                'dt': dt_oracle * 0.5  # æ›´å°çš„æ—¶é—´æ­¥é•¿
            }
        elif mode == 'fix_time':
            return {
                'resolution': 32,
                'degree': 1,
                'dt': dt_oracle * 2.0  # æ›´å¤§çš„æ—¶é—´æ­¥é•¿ï¼ˆä½†ä¿æŒç¨³å®šï¼‰
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—æŠ›ç‰©å‹æ–¹ç¨‹ä¸“ç”¨æŒ‡æ ‡ï¼š
        - efficiency_workrate: å·¥ä½œé€Ÿç‡ (DOF Ã— N_steps) / T_total
        - energy_decay_rate: èƒ½é‡è¡°å‡ç‡ï¼ˆL2èŒƒæ•°åº”å•è°ƒä¸‹é™ï¼‰
        - max_principle_check: æœ€å¤§å€¼åŸç†æ£€æŸ¥
        - time_stepping_efficiency: æ—¶é—´æ­¥è¿›æ•ˆç‡
        - cfl_number: CFL æ•°ï¼ˆéšå¼ç¨³å®šæ€§æŒ‡æ ‡ï¼‰
        """
        metrics = {}
        
        try:
            # 1. è®¡ç®— DOF å’Œæ—¶é—´æ­¥æ•°
            resolution = result.get('test_params', {}).get('resolution', 0)
            degree = result.get('test_params', {}).get('degree', 1)
            
            # ä¿®æ­£ DOF è®¡ç®—
            if degree == 1:
                dof = resolution ** 2
            elif degree == 2:
                dof = (2 * resolution + 1) ** 2
            else:
                dof = resolution ** 2 * degree ** 2
            
            oracle_time_config = self.config['oracle_config']['pde']['time']
            t_end = oracle_time_config['t_end']
            dt = result.get('test_params', {}).get('dt', oracle_time_config['dt'])
            n_steps = int(np.ceil(t_end / dt))
            
            metrics['dof'] = int(dof)
            metrics['n_steps'] = n_steps
            metrics['dt'] = float(dt)
            metrics['t_end'] = float(t_end)
            
            # 2. è®¡ç®— WorkRate
            runtime = result.get('runtime_sec', 0)
            if runtime > 0:
                workrate = (dof * n_steps) / runtime
                metrics['efficiency_workrate'] = float(workrate)
                
                # æ¯æ­¥å¹³å‡æ—¶é—´
                time_per_step = runtime / n_steps
                metrics['time_per_step'] = float(time_per_step)
            
            # 3. CFL æ•°ï¼ˆç½‘æ ¼å°ºå¯¸ï¼Œæ—¶é—´æ­¥é•¿ï¼‰
            h = 1.0 / resolution
            kappa = oracle_time_config.get('kappa', 1.0)
            # çƒ­æ–¹ç¨‹ CFL: dt / (h^2 / Îº)
            cfl = kappa * dt / (h ** 2)
            metrics['cfl_number'] = float(cfl)
            if cfl > 0.5:  # æ˜¾å¼æ ¼å¼çš„ç¨³å®šæ€§æé™
                metrics['cfl_warning'] = f"CFL={cfl:.2f} > 0.5 (æ˜¾å¼æ ¼å¼ä¸ç¨³å®š)"
            
            # 4. è¯»å–è§£çš„æ—¶é—´å†å²
            u_history_file = self.agent_output_dir / 'u_history.npy'
            if u_history_file.exists():
                u_history = np.load(u_history_file)
                
                # èƒ½é‡ï¼ˆL2èŒƒæ•°ï¼‰å†å²
                energy_history = np.array([np.linalg.norm(u_history[i].flatten()) for i in range(len(u_history))])
                
                # æ£€æŸ¥èƒ½é‡å•è°ƒæ€§
                energy_diffs = np.diff(energy_history)
                n_violations = np.sum(energy_diffs > 1e-10)
                
                metrics['energy_monotone'] = bool(n_violations == 0)
                metrics['energy_violations'] = int(n_violations)
                
                # èƒ½é‡è¡°å‡ç‡ï¼ˆæŒ‡æ•°æ‹Ÿåˆ E(t) ~ E0 * exp(-Î»t)ï¼‰
                if energy_history[0] > 1e-14:
                    decay_ratio = (energy_history[0] - energy_history[-1]) / energy_history[0]
                    metrics['energy_decay_ratio'] = float(decay_ratio)
                    
                    # ä¼°è®¡è¡°å‡ç‡ Î»
                    if energy_history[-1] > 1e-14:
                        lambda_estimate = -np.log(energy_history[-1] / energy_history[0]) / t_end
                        metrics['decay_rate_lambda'] = float(lambda_estimate)
                
                # 5. æœ€å¤§å€¼åŸç†æ£€æŸ¥
                # é½æ¬¡ Dirichlet è¾¹ç•Œï¼šmax|u(t)| â‰¤ max|u(0)|
                initial_max = np.max(np.abs(u_history[0]))
                all_max = np.array([np.max(np.abs(u_history[i])) for i in range(len(u_history))])
                final_max = all_max[-1]
                global_max = np.max(all_max)
                
                metrics['initial_max'] = float(initial_max)
                metrics['final_max'] = float(final_max)
                metrics['global_max'] = float(global_max)
                
                # æ£€æŸ¥è¿åï¼ˆå…è®¸å°çš„æ•°å€¼è¯¯å·®ï¼‰
                tolerance = initial_max * 0.01  # 1% å®¹å·®
                if global_max > initial_max + tolerance:
                    metrics['max_principle_violated'] = True
                    metrics['max_principle_overshoot'] = float(global_max - initial_max)
                else:
                    metrics['max_principle_violated'] = False
            
            # 6. è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics


# ConvectionDiffusionCaseTest å·²ç§»é™¤ - åº”ä½¿ç”¨ MixedTypeCaseTest æˆ– EllipticCaseTest + å¯¹åº”æ ‡ç­¾


# ============================================================================
# æ‰©å±• PDE ç±»å‹æµ‹è¯•ç±» (Phase 2)
# ============================================================================

class IncompressibleFlowCaseTest(BaseCaseTest):
    """éç‚¹é—®é¢˜ï¼ˆStokes æ–¹ç¨‹ï¼‰æµ‹è¯•"""
    
    def get_pde_type(self) -> str:
        return 'incompressible_flow'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        Stokes æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - Taylor-Hood å…ƒ (P2-P1) æ»¡è¶³ inf-sup æ¡ä»¶
        - éœ€è¦å—é¢„æ¡ä»¶å™¨ (field-split)
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 64,
                'degree': 2  # é€Ÿåº¦ç©ºé—´é˜¶æ•°ï¼›å‹åŠ›ä¸º degree-1
            }
        elif mode == 'fix_time':
            return {
                'resolution': 32,
                'degree': 1  # é€Ÿåº¦ P1ï¼Œå‹åŠ› P0ï¼ˆMINI element æˆ– stabilizedï¼‰
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—ä¸å¯å‹æµï¼ˆStokes/NSï¼‰ä¸“ç”¨æŒ‡æ ‡ï¼š
        - divergence_L2: ||âˆ‡Â·u||_L2ï¼ˆæ•£åº¦è‡ªç”±åº¦ï¼‰
        - mass_flux_error: âˆ«_Î© âˆ‡Â·u dxï¼ˆå…¨å±€è´¨é‡å®ˆæ’ï¼‰
        - pressure_mean_check: å‹åŠ›å‡å€¼ï¼ˆé›¶ç©ºé—´å¤„ç†ï¼‰
        - inf_sup_stability: inf-sup ç¨³å®šæ€§æŒ‡æ ‡
        - velocity_gradient_L2: ||âˆ‡u||_L2ï¼ˆå‰ªåˆ‡ç‡ï¼‰
        """
        metrics = {}
        
        try:
            # 1. è¯»å–é€Ÿåº¦åœº
            agent_u_file = self.agent_output_dir / 'u.npy'
            if agent_u_file.exists():
                u = np.load(agent_u_file)
                
                # é€Ÿåº¦åœº L2 èŒƒæ•°
                metrics['velocity_L2'] = float(np.linalg.norm(u))
                
                # è®¡ç®—æ•£åº¦ï¼ˆæœ‰é™å·®åˆ†ï¼‰
                if u.ndim >= 3:  # (nx, ny, dim) æˆ– (nx, ny, nz, dim)
                    div_u = self._compute_divergence_fd(u)
                    
                    # æ•£åº¦çš„ L2 èŒƒæ•°ï¼ˆç›¸å¯¹äºé€Ÿåº¦èŒƒæ•°ï¼‰
                    div_L2 = np.linalg.norm(div_u)
                    metrics['divergence_L2'] = float(div_L2)
                    
                    u_L2 = np.linalg.norm(u)
                    if u_L2 > 1e-14:
                        metrics['divergence_relative'] = float(div_L2 / u_L2)
                    
                    # å…¨å±€è´¨é‡é€šé‡è¯¯å·®ï¼ˆç§¯åˆ†ï¼‰
                    # âˆ«_Î© âˆ‡Â·u dx åº”è¯¥ä¸º 0ï¼ˆæˆ–ç­‰äºè¾¹ç•Œé€šé‡ï¼‰
                    mass_flux = np.sum(div_u)
                    metrics['mass_flux_integral'] = float(mass_flux)
                    
                    # ç›¸å¯¹è´¨é‡å®ˆæ’è¯¯å·®
                    # å¯¹äºå°é—­åŸŸï¼š|âˆ« âˆ‡Â·u| / (âˆ« |u|)
                    total_velocity_mag = np.sum(np.abs(u))
                    if total_velocity_mag > 1e-14:
                        mass_error = np.abs(mass_flux) / total_velocity_mag
                        metrics['mass_conservation_error'] = float(mass_error)
                    
                    # é€Ÿåº¦æ¢¯åº¦èŒƒæ•°ï¼ˆå‰ªåˆ‡ç‡ï¼‰
                    grad_u_norm = self._compute_velocity_gradient_norm(u)
                    metrics['velocity_gradient_L2'] = float(grad_u_norm)
            
            # 2. è¯»å–å‹åŠ›åœº
            agent_p_file = self.agent_output_dir / 'p.npy'
            if agent_p_file.exists():
                p = np.load(agent_p_file)
                
                p_L2 = np.linalg.norm(p)
                metrics['pressure_L2'] = float(p_L2)
                
                # å‹åŠ›å‡å€¼ï¼ˆé›¶ç©ºé—´æ£€æŸ¥ï¼‰
                p_mean = np.mean(p)
                p_std = np.std(p)
                
                metrics['pressure_mean'] = float(p_mean)
                metrics['pressure_std'] = float(p_std)
                
                # æ£€æŸ¥æ˜¯å¦å¤„ç†äº†å‹åŠ›å¸¸æ•°ä¸å®šæ€§
                # é€šå¸¸åº”å›ºå®šä¸€ä¸ªç‚¹çš„å‹åŠ›æˆ–å¼ºåˆ¶é›¶å‡å€¼
                if np.abs(p_mean) > 0.01 * p_std:  # å‡å€¼æ˜¾è‘—éé›¶
                    metrics['pressure_mean_enforced'] = False
                else:
                    metrics['pressure_mean_enforced'] = True
            
            # 3. inf-sup ç¨³å®šæ€§æŒ‡æ ‡ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
            # çœŸæ­£çš„ inf-sup å¸¸æ•°éœ€è¦ç‰¹å¾å€¼è®¡ç®—ï¼Œè¿™é‡Œç”¨å¯å‘å¼æŒ‡æ ‡
            if agent_u_file.exists() and agent_p_file.exists():
                u = np.load(agent_u_file)
                p = np.load(agent_p_file)
                div_u = self._compute_divergence_fd(u)
                
                # å‹åŠ›æ¢¯åº¦èŒƒæ•°
                grad_p = self._compute_pressure_gradient_norm(p)
                
                # å¯å‘å¼ inf-sup æŒ‡æ ‡ï¼š||âˆ‡p|| / ||u||
                u_norm = np.linalg.norm(u)
                if u_norm > 1e-14:
                    inf_sup_indicator = grad_p / u_norm
                    metrics['inf_sup_indicator'] = float(inf_sup_indicator)
            
            # 4. è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
    
    def _compute_divergence_fd(self, u: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨æœ‰é™å·®åˆ†è®¡ç®—æ•£åº¦ âˆ‡Â·u"""
        if u.ndim == 3:  # 2D: (nx, ny, 2)
            nx, ny, _ = u.shape
            h = 1.0 / nx
            
            # âˆ‚u_x/âˆ‚x + âˆ‚u_y/âˆ‚y
            du_x = np.gradient(u[:, :, 0], h, axis=0)
            du_y = np.gradient(u[:, :, 1], h, axis=1)
            div_u = du_x + du_y
            
            return div_u
        else:
            return np.zeros_like(u[:, :, 0])
    
    def _compute_velocity_gradient_norm(self, u: np.ndarray) -> float:
        """è®¡ç®—é€Ÿåº¦æ¢¯åº¦èŒƒæ•° ||âˆ‡u||_L2"""
        try:
            if u.ndim == 3:  # 2D: (nx, ny, 2)
                nx, ny, _ = u.shape
                h = 1.0 / nx
                
                # âˆ‚u_x/âˆ‚x, âˆ‚u_x/âˆ‚y, âˆ‚u_y/âˆ‚x, âˆ‚u_y/âˆ‚y
                du_x_dx = np.gradient(u[:, :, 0], h, axis=0)
                du_x_dy = np.gradient(u[:, :, 0], h, axis=1)
                du_y_dx = np.gradient(u[:, :, 1], h, axis=0)
                du_y_dy = np.gradient(u[:, :, 1], h, axis=1)
                
                # Frobenius èŒƒæ•°ï¼šsqrt(sum of all gradients squared)
                grad_norm_sq = du_x_dx**2 + du_x_dy**2 + du_y_dx**2 + du_y_dy**2
                return np.sqrt(np.sum(grad_norm_sq))
            else:
                return 0.0
        except:
            return 0.0
    
    def _compute_pressure_gradient_norm(self, p: np.ndarray) -> float:
        """è®¡ç®—å‹åŠ›æ¢¯åº¦èŒƒæ•° ||âˆ‡p||_L2"""
        try:
            if p.ndim == 2:  # 2D: (nx, ny)
                nx, ny = p.shape
                h = 1.0 / nx
                
                # âˆ‚p/âˆ‚x, âˆ‚p/âˆ‚y
                dp_dx = np.gradient(p, h, axis=0)
                dp_dy = np.gradient(p, h, axis=1)
                
                grad_norm_sq = dp_dx**2 + dp_dy**2
                return np.sqrt(np.sum(grad_norm_sq))
            else:
                return 0.0
        except:
            return 0.0


# HelmholtzCaseTest å·²ç§»é™¤ - åº”ä½¿ç”¨ EllipticCaseTest + structure: symmetric_indefinite æ ‡ç­¾


class HyperbolicCaseTest(BaseCaseTest):
    """åŒæ›²å‹ä¸€é˜¶ï¼ˆå¯¹æµ/å®ˆæ’å¾‹ï¼‰æµ‹è¯•"""
    
    def get_pde_type(self) -> str:
        return 'hyperbolic'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        åŒæ›²æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - ä¸Šé£æ ¼å¼ / DG / flux limiter
        - æ—¶é—´æ­¥éœ€æ»¡è¶³ CFL æ¡ä»¶
        """
        # ä» config è¯»å–å¯¹æµé€Ÿåº¦å’Œ CFL
        pde_config = self.config.get('oracle_config', {}).get('pde', {})
        cfl_target = pde_config.get('cfl', 0.5)  # é»˜è®¤ CFL = 0.5
        
        if mode == 'fix_accuracy':
            resolution = 128
            h = 1.0 / resolution
            dt = cfl_target * h  # CFL æ¡ä»¶
            return {
                'resolution': resolution,
                'degree': 1,
                'dt': dt
            }
        elif mode == 'fix_time':
            resolution = 64
            h = 1.0 / resolution
            dt = cfl_target * h
            return {
                'resolution': resolution,
                'degree': 1,
                'dt': dt
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—åŒæ›²æ–¹ç¨‹ä¸“ç”¨æŒ‡æ ‡ï¼š
        - overshoot/undershoot: éç‰©ç†éœ‡è¡ï¼ˆè¿åæœ€å¤§å€¼åŸç†ï¼‰
        - tv_growth: TV(u_final) / TV(u_initial) - TVD æ ¼å¼åº” â‰¤ 1
        - mass_conservation_error: å®ˆæ’å¾‹æ£€æŸ¥
        - shock_resolution: æ¿€æ³¢åˆ†è¾¨ç‡
        - cfl_number: CFL æ•°
        """
        metrics = {}
        
        try:
            # è¯»å–è§£
            agent_u_file = self.agent_output_dir / 'u.npy'
            oracle_u_file = self.oracle_output_dir / 'u.npy'
            
            if agent_u_file.exists() and oracle_u_file.exists():
                u_agent = np.load(agent_u_file)
                u_oracle = np.load(oracle_u_file)
                
                # 1. è¶…è°ƒ/æ¬ è°ƒï¼ˆç›¸å¯¹äº oracle çš„èŒƒå›´ï¼‰
                u_max_ref = np.max(u_oracle)
                u_min_ref = np.min(u_oracle)
                
                overshoot = max(0.0, np.max(u_agent) - u_max_ref)
                undershoot = max(0.0, u_min_ref - np.min(u_agent))
                
                metrics['overshoot'] = float(overshoot)
                metrics['undershoot'] = float(undershoot)
                
                # ç›¸å¯¹éœ‡è¡å¼ºåº¦
                solution_range = u_max_ref - u_min_ref
                if solution_range > 1e-14:
                    metrics['overshoot_relative'] = float(overshoot / solution_range)
                    metrics['undershoot_relative'] = float(undershoot / solution_range)
                
                # 2. æ€»å˜å·®ï¼ˆTVï¼‰
                tv_agent = self._compute_total_variation(u_agent)
                metrics['total_variation'] = float(tv_agent)
                
                # TV å¢é•¿ç‡ï¼ˆTVD æ£€æŸ¥ï¼‰
                agent_u0_file = self.agent_output_dir / 'u_initial.npy'
                if agent_u0_file.exists():
                    u0 = np.load(agent_u0_file)
                    tv_initial = self._compute_total_variation(u0)
                    
                    if tv_initial > 1e-14:
                        tv_growth = tv_agent / tv_initial
                        metrics['tv_growth_ratio'] = float(tv_growth)
                        
                        if tv_growth > 1.01:  # å…è®¸ 1% æ•°å€¼è¯¯å·®
                            metrics['tvd_violated'] = True
                        else:
                            metrics['tvd_violated'] = False
                    
                    # 3. è´¨é‡å®ˆæ’
                    mass_initial = np.sum(u0)
                    mass_final = np.sum(u_agent)
                    
                    if np.abs(mass_initial) > 1e-14:
                        mass_error = np.abs(mass_final - mass_initial) / np.abs(mass_initial)
                        metrics['mass_conservation_error'] = float(mass_error)
                
                # 4. æ¿€æ³¢åˆ†è¾¨ç‡
                shock_width = self._compute_shock_width(u_agent)
                metrics['shock_width_points'] = float(shock_width)
                
                # ç›¸å¯¹æ¿€æ³¢å®½åº¦ï¼ˆç›¸å¯¹äºç½‘æ ¼å°ºå¯¸ï¼‰
                resolution = result.get('test_params', {}).get('resolution', 0)
                if resolution > 0 and shock_width > 0:
                    h = 1.0 / resolution
                    shock_width_physical = shock_width * h
                    metrics['shock_width_physical'] = float(shock_width_physical)
            
            # 5. CFL æ•°
            resolution = result.get('test_params', {}).get('resolution', 0)
            dt = result.get('test_params', {}).get('dt', 0)
            pde_config = self.config.get('oracle_config', {}).get('pde', {})
            advection_speed = pde_config.get('advection_speed', 1.0)
            
            if resolution > 0 and dt > 0:
                h = 1.0 / resolution
                cfl = advection_speed * dt / h
                metrics['cfl_number'] = float(cfl)
                
                if cfl > 1.0:
                    metrics['cfl_warning'] = f"CFL={cfl:.2f} > 1.0 (å¯èƒ½ä¸ç¨³å®š)"
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
    
    def _compute_total_variation(self, u: np.ndarray) -> float:
        """è®¡ç®—æ€»å˜å·® TV(u)"""
        if u.ndim == 1:
            return np.sum(np.abs(np.diff(u)))
        elif u.ndim == 2:
            tv_x = np.sum(np.abs(np.diff(u, axis=0)))
            tv_y = np.sum(np.abs(np.diff(u, axis=1)))
            return tv_x + tv_y
        else:
            return 0.0

    def _compute_shock_width(self, u: np.ndarray) -> float:
        """
        ä¼°ç®—æ¿€æ³¢å®½åº¦ï¼ˆå ç”¨çš„ç½‘æ ¼ç‚¹æ•°ï¼‰
        ç®—æ³•ï¼šæ‰¾åˆ°æ¢¯åº¦æœ€å¤§çš„ä½ç½®ï¼Œè®¡ç®—ä» 10% åˆ° 90% è·³å˜æ‰€éœ€çš„è·ç¦»
        """
        try:
            if u.ndim != 1:
                return 0.0  # ç›®å‰åªæ”¯æŒ 1D æ¿€æ³¢å®½åº¦è®¡ç®—
            
            # è®¡ç®—æ¢¯åº¦ç»å¯¹å€¼
            grad = np.abs(np.gradient(u))
            max_grad_idx = np.argmax(grad)
            max_grad = grad[max_grad_idx]
            
            if max_grad < 1e-6:
                return 0.0  # æ²¡æœ‰æ˜æ˜¾çš„æ¢¯åº¦/æ¿€æ³¢
            
            # ä»¥æœ€å¤§æ¢¯åº¦ç‚¹ä¸ºä¸­å¿ƒï¼Œå‘å·¦å³æœç´¢
            # å®šä¹‰æ¿€æ³¢çš„ä¸Šä¸‹ç•Œï¼šå–è§£çš„ min å’Œ max
            u_min, u_max = np.min(u), np.max(u)
            jump = u_max - u_min
            if jump < 1e-6:
                return 0.0
                
            # ç®€å•çš„åŠé«˜å®½ä¼°è®¡ FWHM æˆ– 10-90% Rise Distance
            # è¿™é‡Œä½¿ç”¨æ¢¯åº¦åˆ†å¸ƒçš„å®½åº¦ï¼šæœ‰å¤šå°‘ä¸ªç‚¹çš„æ¢¯åº¦ > max_grad * 0.1
            width_points = np.sum(grad > max_grad * 0.1)
            return float(width_points)
            
        except:
            return 0.0




# ============================================================================
# æ–°å¢çš„8ä¸ªæ ‡å‡† PDE ç±»å‹æµ‹è¯•ç±»
# ============================================================================

class MixedTypeCaseTest(BaseCaseTest):
    """
    æ··åˆå‹æ–¹ç¨‹æµ‹è¯•ï¼ˆå¦‚å¯¹æµæ‰©æ•£æ–¹ç¨‹ï¼Œéšå‚æ•°å¯åœ¨æ¤­åœ†/åŒæ›²é—´åˆ‡æ¢ï¼‰
    
    ä¸»è¦é’ˆå¯¹å¯¹æµæ‰©æ•£æ–¹ç¨‹ï¼š-Îµâˆ†u + bÂ·âˆ‡u = f
    - å½“ Îµ >> ||b|| æ—¶è¡¨ç°ä¸ºæ¤­åœ†å‹ï¼ˆæ‰©æ•£ä¸»å¯¼ï¼‰
    - å½“ Îµ << ||b|| æ—¶è¡¨ç°ä¸ºåŒæ›²å‹ï¼ˆå¯¹æµä¸»å¯¼ï¼‰
    """
    
    def get_pde_type(self) -> str:
        return 'mixed_type'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        å¯¹æµæ‰©æ•£å‚æ•°æ¨èï¼š
        - éœ€è¦ç¨³å®šåŒ–ï¼ˆSUPG/Upwindï¼‰
        - é«˜ PÃ©clet æ•°éœ€è¦æ›´é«˜åˆ†è¾¨ç‡æˆ–ç¨³å®šåŒ–
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 128,
                'degree': 2
            }
        elif mode == 'fix_time':
            return {
                'resolution': 64,
                'degree': 1
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—å¯¹æµæ‰©æ•£ä¸“ç”¨æŒ‡æ ‡ï¼š
        - peclet_number: PÃ©clet æ•° Pe = ||b||L/Îµ
        - overshoot/undershoot: éç‰©ç†éœ‡è¡æŒ‡æ ‡
        - boundary_layer_resolution: è¾¹ç•Œå±‚åˆ†è¾¨ç‡
        - stabilization_quality: ç¨³å®šåŒ–æ•ˆæœè¯„ä¼°
        """
        metrics = {}
        
        try:
            # è¯»å– PÃ©clet æ•°
            pde_config = self.config.get('oracle_config', {}).get('pde', {})
            peclet = pde_config.get('peclet', None)
            if peclet is not None:
                metrics['peclet_number'] = float(peclet)
            
            # è¯»å–è§£
            agent_u_file = self.agent_output_dir / 'u.npy'
            oracle_u_file = self.oracle_output_dir / 'u.npy'
            
            if agent_u_file.exists() and oracle_u_file.exists():
                u_agent = np.load(agent_u_file)
                u_oracle = np.load(oracle_u_file)
                
                # 1. è¶…è°ƒ/æ¬ è°ƒæŒ‡æ ‡
                u_max_ref = np.max(u_oracle)
                u_min_ref = np.min(u_oracle)
                
                overshoot = np.max([0.0, np.max(u_agent) - u_max_ref])
                undershoot = np.max([0.0, u_min_ref - np.min(u_agent)])
                
                metrics['overshoot'] = float(overshoot)
                metrics['undershoot'] = float(undershoot)
                
                solution_range = u_max_ref - u_min_ref
                if solution_range > 1e-14:
                    metrics['overshoot_relative'] = float(overshoot / solution_range)
                    metrics['undershoot_relative'] = float(undershoot / solution_range)
                
                # 2. æ€»å˜å·®ï¼ˆæ£€æµ‹ Gibbs éœ‡è¡ï¼‰
                tv_agent = self._compute_total_variation(u_agent)
                tv_oracle = self._compute_total_variation(u_oracle)
                
                metrics['total_variation'] = float(tv_agent)
                if tv_oracle > 1e-14:
                    metrics['tv_ratio'] = float(tv_agent / tv_oracle)
                
                # 3. è¾¹ç•Œå±‚è¯¯å·®
                if peclet is not None and peclet > 1:
                    bl_error = self._compute_boundary_layer_error(u_agent, u_oracle, peclet)
                    if bl_error is not None:
                        metrics['boundary_layer_error'] = float(bl_error)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
    
    def _compute_total_variation(self, u: np.ndarray) -> float:
        """è®¡ç®—æ€»å˜å·® TV(u)"""
        if u.ndim == 1:
            return float(np.sum(np.abs(np.diff(u))))
        elif u.ndim == 2:
            tv_x = np.sum(np.abs(np.diff(u, axis=0)))
            tv_y = np.sum(np.abs(np.diff(u, axis=1)))
            return float(tv_x + tv_y)
        else:
            return 0.0
    
    def _compute_boundary_layer_error(self, u_agent: np.ndarray, u_oracle: np.ndarray, peclet: float) -> Optional[float]:
        """è®¡ç®—è¾¹ç•Œå±‚åŒºåŸŸçš„è¯¯å·®"""
        try:
            if u_agent.ndim == 1:
                nx = len(u_agent)
                epsilon = 1.0 / (peclet + 1e-10)
                bl_thickness = 3 * epsilon
                bl_points = int(bl_thickness * nx)
                bl_points = max(bl_points, 5)
                bl_points = min(bl_points, nx // 4)
                
                err_left = np.linalg.norm(u_agent[:bl_points] - u_oracle[:bl_points])
                err_right = np.linalg.norm(u_agent[-bl_points:] - u_oracle[-bl_points:])
                
                return max(err_left, err_right)
            else:
                return None
        except:
            return None


class DispersiveCaseTest(BaseCaseTest):
    """
    è‰²æ•£å‹æ–¹ç¨‹æµ‹è¯•ï¼ˆSchrÃ¶dinger, KdV ç­‰ï¼‰
    
    æ ¸å¿ƒç‰¹å¾ï¼š
    - ç›¸é€Ÿåº¦ â‰  ç¾¤é€Ÿåº¦
    - éœ€è¦ä¿æŒç›¸ä½å…³ç³»
    - é€šå¸¸éœ€è¦å¤æ•°è¿ç®—æˆ–ç‰¹æ®Šæ—¶é—´ç§¯åˆ†
    """
    
    def get_pde_type(self) -> str:
        return 'dispersive'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        è‰²æ•£æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - é«˜é˜¶ç©ºé—´ç¦»æ•£ï¼ˆè‡³å°‘ P2 æˆ– spectralï¼‰
        - å°æ—¶é—´æ­¥é•¿ä»¥æ•æ‰é«˜é¢‘æ¨¡å¼
        - å¯¹ç§°æ—¶é—´ç§¯åˆ†æ ¼å¼ï¼ˆCrank-Nicolson, Strang splittingï¼‰
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 256,  # éœ€è¦é«˜åˆ†è¾¨ç‡
                'degree': 2,
                'dt': 0.0001  # å°æ—¶é—´æ­¥é•¿
            }
        elif mode == 'fix_time':
            return {
                'resolution': 128,
                'degree': 1,
                'dt': 0.001
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—è‰²æ•£æ–¹ç¨‹ä¸“ç”¨æŒ‡æ ‡ï¼š
        - phase_velocity_error: ç›¸é€Ÿåº¦è¯¯å·®
        - group_velocity_error: ç¾¤é€Ÿåº¦è¯¯å·®
        - dispersion_error: è‰²æ•£å…³ç³»è¯¯å·®
        - mass_conservation: è´¨é‡å®ˆæ’ï¼ˆSchrÃ¶dinger: âˆ«|Ïˆ|Â²dxï¼‰
        - energy_conservation: èƒ½é‡å®ˆæ’
        """
        metrics = {}
        
        try:
            # è¯»å–è§£
            agent_u_file = self.agent_output_dir / 'u.npy'
            oracle_u_file = self.oracle_output_dir / 'u.npy'
            
            if agent_u_file.exists() and oracle_u_file.exists():
                u_agent = np.load(agent_u_file)
                u_oracle = np.load(oracle_u_file)
                
                # 1. è´¨é‡å®ˆæ’ï¼ˆL2èŒƒæ•°ï¼‰
                mass_agent = np.linalg.norm(u_agent)
                mass_oracle = np.linalg.norm(u_oracle)
                
                metrics['mass_agent'] = float(mass_agent)
                metrics['mass_oracle'] = float(mass_oracle)
                
                if mass_oracle > 1e-14:
                    mass_error = np.abs(mass_agent - mass_oracle) / mass_oracle
                    metrics['mass_conservation_error'] = float(mass_error)
                
                # 2. ç›¸ä½è¯¯å·®ï¼ˆæ³¢å³°ä½ç½®ï¼‰
                phase_error = self._compute_phase_error(u_agent, u_oracle)
                metrics['phase_error'] = float(phase_error)
                
                # 3. é¢‘è°±æ¯”è¾ƒï¼ˆå¦‚æœè§£æ˜¯å‘¨æœŸçš„ï¼‰
                if u_agent.ndim == 1:
                    spectrum_error = self._compute_spectrum_error(u_agent, u_oracle)
                    if spectrum_error is not None:
                        metrics['spectrum_error'] = float(spectrum_error)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
    
    def _compute_phase_error(self, u_agent: np.ndarray, u_oracle: np.ndarray) -> float:
        """è®¡ç®—ç›¸ä½è¯¯å·®"""
        try:
            idx_agent = np.argmax(np.abs(u_agent))
            idx_oracle = np.argmax(np.abs(u_oracle))
            
            if u_agent.ndim == 1:
                return np.abs(idx_agent - idx_oracle) / u_agent.shape[0]
            elif u_agent.ndim == 2:
                row_a, col_a = np.unravel_index(idx_agent, u_agent.shape)
                row_o, col_o = np.unravel_index(idx_oracle, u_oracle.shape)
                return np.sqrt((row_a - row_o)**2 + (col_a - col_o)**2) / u_agent.shape[0]
            else:
                return 0.0
        except:
            return 0.0
    
    def _compute_spectrum_error(self, u_agent: np.ndarray, u_oracle: np.ndarray) -> Optional[float]:
        """è®¡ç®—é¢‘è°±è¯¯å·®"""
        try:
            if u_agent.ndim != 1:
                return None
            
            # FFT
            fft_agent = np.fft.fft(u_agent)
            fft_oracle = np.fft.fft(u_oracle)
            
            # L2 è¯¯å·®åœ¨é¢‘åŸŸ
            spectrum_error = np.linalg.norm(fft_agent - fft_oracle) / np.linalg.norm(fft_oracle)
            return spectrum_error
        except:
            return None


class ReactionDiffusionCaseTest(BaseCaseTest):
    """
    ååº”æ‰©æ•£æ–¹ç¨‹æµ‹è¯•ï¼ˆAllen-Cahn, Fisher-KPP, Gray-Scott ç­‰ï¼‰
    
    æ ¸å¿ƒæŒ‘æˆ˜ï¼š
    - éçº¿æ€§ååº”é¡¹çš„åˆšæ€§
    - æ¨¡å¼å½¢æˆï¼ˆpattern formationï¼‰
    - è¡Œæ³¢è§£çš„ä¼ æ’­é€Ÿåº¦
    - èƒ½é‡å®šå¾‹
    """
    
    def get_pde_type(self) -> str:
        return 'reaction_diffusion'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        ååº”æ‰©æ•£å‚æ•°æ¨èï¼š
        - IMEX æ—¶é—´ç§¯åˆ†ï¼ˆéšå¼æ‰©æ•£ + æ˜¾å¼ååº”ï¼‰
        - è‡ªé€‚åº”æ—¶é—´æ­¥é•¿
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 128,
                'degree': 2,
                'dt': 0.001
            }
        elif mode == 'fix_time':
            return {
                'resolution': 64,
                'degree': 1,
                'dt': 0.01
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—ååº”æ‰©æ•£ä¸“ç”¨æŒ‡æ ‡ï¼š
        - energy_decay: è‡ªç”±èƒ½å•è°ƒé€’å‡ï¼ˆAllen-Cahnï¼‰
        - mass_conservation: è´¨é‡å®ˆæ’ï¼ˆæŸäº›æ¨¡å‹ï¼‰
        - front_propagation_speed: è¡Œæ³¢ä¼ æ’­é€Ÿåº¦
        - pattern_quality: æ¨¡å¼å½¢æˆè´¨é‡
        - nonlinear_solver_efficiency: éçº¿æ€§è¿­ä»£æ•ˆç‡
        """
        metrics = {}
        
        try:
            # è¯»å– meta.json
            meta_file = self.agent_output_dir / 'meta.json'
            if meta_file.exists():
                with open(meta_file) as f:
                    meta = json.load(f)
                
                # 1. éçº¿æ€§è¿­ä»£
                if 'nonlinear_solver' in meta:
                    ns = meta['nonlinear_solver']
                    if isinstance(ns, dict) and 'iterations' in ns:
                        iters = ns['iterations']
                        if isinstance(iters, list):
                            metrics['newton_iterations_mean'] = float(np.mean(iters))
                            metrics['newton_iterations_max'] = int(np.max(iters))
                
                # 2. èƒ½é‡æ¼”åŒ–
                if 'energy_history' in meta:
                    energy = np.array(meta['energy_history'])
                    
                    energy_diffs = np.diff(energy)
                    n_violations = np.sum(energy_diffs > 1e-10)
                    
                    metrics['energy_monotone'] = bool(n_violations == 0)
                    metrics['energy_violations'] = int(n_violations)
                    
                    if len(energy) > 1 and np.abs(energy[0]) > 1e-14:
                        decay_ratio = (energy[0] - energy[-1]) / np.abs(energy[0])
                        metrics['energy_decay_ratio'] = float(decay_ratio)
            
            # 3. è´¨é‡å®ˆæ’
            u0_file = self.agent_output_dir / 'u_initial.npy'
            u_final_file = self.agent_output_dir / 'u.npy'
            
            if u0_file.exists() and u_final_file.exists():
                u0 = np.load(u0_file)
                u_final = np.load(u_final_file)
                
                mass0 = np.sum(u0)
                mass_final = np.sum(u_final)
                
                if np.abs(mass0) > 1e-14:
                    mass_error = np.abs(mass_final - mass0) / np.abs(mass0)
                    metrics['mass_conservation_error'] = float(mass_error)
            
            # 4. è¡Œæ³¢ä¼ æ’­é€Ÿåº¦ï¼ˆå¦‚æœæœ‰åˆå§‹å’Œæœ€ç»ˆçŠ¶æ€ï¼‰
            if u0_file.exists() and u_final_file.exists():
                u0 = np.load(u0_file)
                u_final = np.load(u_final_file)
                
                front_speed = self._estimate_front_speed(u0, u_final, result)
                if front_speed is not None:
                    metrics['front_propagation_speed'] = float(front_speed)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
    
    def _estimate_front_speed(self, u0: np.ndarray, u_final: np.ndarray, result: Dict) -> Optional[float]:
        """ä¼°ç®—è¡Œæ³¢ä¼ æ’­é€Ÿåº¦"""
        try:
            if u0.ndim != 1:
                return None
            
            # æ‰¾åˆ°åŠé«˜ç‚¹çš„ä½ç½®
            threshold = 0.5 * (np.max(u0) + np.min(u0))
            
            front_idx_0 = np.argmax(u0 > threshold)
            front_idx_final = np.argmax(u_final > threshold)
            
            dx = 1.0 / len(u0)
            distance = (front_idx_final - front_idx_0) * dx
            
            # æ€»æ—¶é—´
            pde_config = self.config.get('oracle_config', {}).get('pde', {})
            if 'time' in pde_config:
                t_end = pde_config['time'].get('t_end', 1.0)
                speed = distance / t_end
                return speed
            else:
                return None
        except:
            return None


class CompressibleFlowCaseTest(BaseCaseTest):
    """
    å¯å‹ç¼©æµæµ‹è¯•ï¼ˆEuler æ–¹ç¨‹ï¼Œå¯å‹ç¼© Navier-Stokesï¼‰
    
    æ ¸å¿ƒæŒ‘æˆ˜ï¼š
    - æ¿€æ³¢æ•æ‰
    - ç†µæ¡ä»¶
    - å¯†åº¦æ­£æ€§ä¿æŒ
    - é«˜ Mach æ•°ç¨³å®šæ€§
    """
    
    def get_pde_type(self) -> str:
        return 'compressible_flow'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        å¯å‹ç¼©æµå‚æ•°æ¨èï¼š
        - é«˜åˆ†è¾¨ç‡æ¿€æ³¢æ•æ‰æ ¼å¼ï¼ˆWENO, TVDï¼‰
        - CFL æ¡ä»¶
        - Riemann solver
        """
        pde_config = self.config.get('oracle_config', {}).get('pde', {})
        cfl = pde_config.get('cfl', 0.5)
        
        if mode == 'fix_accuracy':
            resolution = 256
            h = 1.0 / resolution
            dt = cfl * h
            return {
                'resolution': resolution,
                'degree': 2,
                'dt': dt
            }
        elif mode == 'fix_time':
            resolution = 128
            h = 1.0 / resolution
            dt = cfl * h
            return {
                'resolution': resolution,
                'degree': 1,
                'dt': dt
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—å¯å‹ç¼©æµä¸“ç”¨æŒ‡æ ‡ï¼š
        - shock_resolution: æ¿€æ³¢åˆ†è¾¨ç‡
        - density_positivity: å¯†åº¦æ­£æ€§ä¿æŒ
        - entropy_production: ç†µäº§ç”Ÿï¼ˆåº”éè´Ÿï¼‰
        - mass/momentum/energy_conservation: å®ˆæ’å¾‹
        - mach_number: Mach æ•°
        """
        metrics = {}
        
        try:
            # è¯»å–å¯†åº¦åœº
            agent_rho_file = self.agent_output_dir / 'rho.npy'
            oracle_rho_file = self.oracle_output_dir / 'rho.npy'
            
            if agent_rho_file.exists():
                rho_agent = np.load(agent_rho_file)
                
                # 1. å¯†åº¦æ­£æ€§æ£€æŸ¥
                rho_min = np.min(rho_agent)
                metrics['density_min'] = float(rho_min)
                metrics['density_positive'] = bool(rho_min > -1e-10)
                
                if rho_min < 0:
                    metrics['density_positivity_violation'] = float(np.abs(rho_min))
                
                # 2. æ¿€æ³¢åˆ†è¾¨ç‡
                if rho_agent.ndim == 1:
                    shock_width = self._compute_shock_width(rho_agent)
                    metrics['shock_width'] = float(shock_width)
            
            # 3. å®ˆæ’å¾‹æ£€æŸ¥
            mass_error = self._check_mass_conservation()
            if mass_error is not None:
                metrics['mass_conservation_error'] = float(mass_error)
            
            # 4. Mach æ•°
            pde_config = self.config.get('oracle_config', {}).get('pde', {})
            mach = pde_config.get('mach', None)
            if mach is not None:
                metrics['mach_number'] = float(mach)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
    
    def _compute_shock_width(self, rho: np.ndarray) -> float:
        """ä¼°ç®—æ¿€æ³¢å®½åº¦"""
        try:
            grad = np.abs(np.gradient(rho))
            max_grad = np.max(grad)
            
            if max_grad < 1e-6:
                return 0.0
            
            width_points = np.sum(grad > max_grad * 0.1)
            return float(width_points)
        except:
            return 0.0
    
    def _check_mass_conservation(self) -> Optional[float]:
        """æ£€æŸ¥è´¨é‡å®ˆæ’"""
        try:
            rho0_file = self.agent_output_dir / 'rho_initial.npy'
            rho_final_file = self.agent_output_dir / 'rho.npy'
            
            if rho0_file.exists() and rho_final_file.exists():
                rho0 = np.load(rho0_file)
                rho_final = np.load(rho_final_file)
                
                mass0 = np.sum(rho0)
                mass_final = np.sum(rho_final)
                
                if np.abs(mass0) > 1e-14:
                    return np.abs(mass_final - mass0) / np.abs(mass0)
            
            return None
        except:
            return None


class KineticCaseTest(BaseCaseTest):
    """
    åŠ¨ç†å­¦æ–¹ç¨‹æµ‹è¯•ï¼ˆVlasov, Boltzmann, Fokker-Planckï¼‰
    
    æ ¸å¿ƒæŒ‘æˆ˜ï¼š
    - é«˜ç»´ç›¸ç©ºé—´ç¦»æ•£
    - è´¨é‡/åŠ¨é‡/èƒ½é‡å®ˆæ’
    - ç†µå¢åŸç†
    - è®¡ç®—ä»£ä»·æé«˜
    """
    
    def get_pde_type(self) -> str:
        return 'kinetic'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        åŠ¨ç†å­¦æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - ç›¸ç©ºé—´ç½‘æ ¼ï¼ˆx, vï¼‰
        - åŠæ‹‰æ ¼æœ—æ—¥æˆ–è°±æ–¹æ³•
        """
        if mode == 'fix_accuracy':
            return {
                'resolution_x': 64,  # ç‰©ç†ç©ºé—´
                'resolution_v': 64,  # é€Ÿåº¦ç©ºé—´
                'degree': 2,
                'dt': 0.01
            }
        elif mode == 'fix_time':
            return {
                'resolution_x': 32,
                'resolution_v': 32,
                'degree': 1,
                'dt': 0.05
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—åŠ¨ç†å­¦æ–¹ç¨‹ä¸“ç”¨æŒ‡æ ‡ï¼š
        - mass_conservation: âˆ«f dxdv = const
        - momentum_conservation: âˆ«vÂ·f dxdv = const
        - energy_conservation: âˆ«vÂ²Â·f dxdv = const
        - entropy_production: ç†µå¢ï¼ˆHå®šç†ï¼‰
        - computational_cost: è®¡ç®—æˆæœ¬ï¼ˆDOF å¾ˆå¤§ï¼‰
        """
        metrics = {}
        
        try:
            # è¯»å–åˆ†å¸ƒå‡½æ•° f(x, v)
            agent_f_file = self.agent_output_dir / 'f.npy'
            
            if agent_f_file.exists():
                f_agent = np.load(agent_f_file)
                
                # å‡è®¾ f çš„å½¢çŠ¶ä¸º (nx, nv)
                if f_agent.ndim == 2:
                    nx, nv = f_agent.shape
                    
                    # è®¡ç®—å®è§‚é‡ï¼ˆç®€åŒ–ï¼šå‡è®¾ v âˆˆ [-v_max, v_max]ï¼‰
                    v_max = 5.0  # ä»é…ç½®è¯»å–
                    dv = 2 * v_max / nv
                    v_grid = np.linspace(-v_max, v_max, nv)
                    
                    # å¯†åº¦ï¼šÏ(x) = âˆ«f dv
                    rho = np.sum(f_agent, axis=1) * dv
                    metrics['total_mass'] = float(np.sum(rho))
                    
                    # åŠ¨é‡ï¼šm(x) = âˆ«vÂ·f dv
                    momentum = np.sum(f_agent * v_grid[None, :], axis=1) * dv
                    metrics['total_momentum'] = float(np.sum(momentum))
                    
                    # èƒ½é‡ï¼šE = âˆ«vÂ²Â·f dv
                    energy = np.sum(f_agent * (v_grid[None, :]**2), axis=1) * dv
                    metrics['total_energy'] = float(np.sum(energy))
            
            # æ£€æŸ¥å®ˆæ’æ€§ï¼ˆéœ€è¦åˆå§‹çŠ¶æ€ï¼‰
            f0_file = self.agent_output_dir / 'f_initial.npy'
            if f0_file.exists() and agent_f_file.exists():
                f0 = np.load(f0_file)
                f_final = np.load(agent_f_file)
                
                if f0.ndim == 2:
                    nx, nv = f0.shape
                    v_max = 5.0
                    dv = 2 * v_max / nv
                    
                    mass0 = np.sum(f0) * dv
                    mass_final = np.sum(f_final) * dv
                    
                    if np.abs(mass0) > 1e-14:
                        mass_error = np.abs(mass_final - mass0) / np.abs(mass0)
                        metrics['mass_conservation_error'] = float(mass_error)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics


class FractionalCaseTest(BaseCaseTest):
    """
    åˆ†æ•°é˜¶ PDE æµ‹è¯•ï¼ˆåˆ†æ•° Laplacian, Caputo å¯¼æ•°ï¼‰
    
    æ ¸å¿ƒæŒ‘æˆ˜ï¼š
    - éå±€éƒ¨ç®—å­çš„è®¡ç®—
    - ç¨ å¯†çŸ©é˜µ
    - è¾¹ç•Œæ¡ä»¶å¤„ç†
    - æ”¶æ•›é˜¶ä¸åˆ†æ•°é˜¶çš„å…³ç³»
    """
    
    def get_pde_type(self) -> str:
        return 'fractional'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        åˆ†æ•°é˜¶æ–¹ç¨‹å‚æ•°æ¨èï¼š
        - éœ€è¦ç‰¹æ®Šçš„æ±‚ç§¯å…¬å¼
        - è®¡ç®—æˆæœ¬é«˜ï¼ˆéå±€éƒ¨ï¼‰
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 128,
                'degree': 2,
                'dt': 0.001  # å¦‚æœæœ‰æ—¶é—´æ¼”åŒ–
            }
        elif mode == 'fix_time':
            return {
                'resolution': 64,
                'degree': 1,
                'dt': 0.01
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—åˆ†æ•°é˜¶æ–¹ç¨‹ä¸“ç”¨æŒ‡æ ‡ï¼š
        - fractional_order_alpha: åˆ†æ•°é˜¶å‚æ•° Î±
        - convergence_rate: æ”¶æ•›é˜¶ï¼ˆä¸ Î± ç›¸å…³ï¼‰
        - computational_cost_ratio: ç›¸å¯¹æ ‡å‡†æ–¹æ³•çš„è®¡ç®—æˆæœ¬
        - matrix_sparsity: çŸ©é˜µç¨€ç–æ€§ï¼ˆé€šå¸¸å¾ˆä½ï¼‰
        """
        metrics = {}
        
        try:
            # è¯»å–åˆ†æ•°é˜¶å‚æ•°
            pde_config = self.config.get('oracle_config', {}).get('pde', {})
            alpha = pde_config.get('fractional_alpha', None)
            if alpha is not None:
                metrics['fractional_order_alpha'] = float(alpha)
            
            # è®¡ç®— DOFï¼ˆåˆ†æ•°é˜¶é€šå¸¸éœ€è¦å…¨å±€è‡ªç”±åº¦ï¼‰
            resolution = result.get('test_params', {}).get('resolution', 0)
            degree = result.get('test_params', {}).get('degree', 1)
            dof = (resolution * degree) ** 2
            metrics['dof'] = int(dof)
            
            # è®¡ç®—æ•ˆç‡ï¼ˆåˆ†æ•°é˜¶æ–¹æ³•é€šå¸¸æ…¢ï¼‰
            runtime = result.get('runtime_sec', 0)
            if runtime > 0:
                efficiency = dof / runtime
                metrics['efficiency_dof_per_sec'] = float(efficiency)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
                
                # æ£€æŸ¥çŸ©é˜µå¡«å……åº¦
                if 'matrix_nnz' in solver_info and 'dof' in metrics:
                    nnz = solver_info['matrix_nnz']
                    dof = metrics['dof']
                    sparsity = 1.0 - nnz / (dof ** 2)
                    metrics['matrix_sparsity'] = float(sparsity)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics


class StochasticCaseTest(BaseCaseTest):
    """
    éšæœº PDE æµ‹è¯•ï¼ˆSPDE: å¸¦éšæœºå¼ºè¿«æˆ–ç³»æ•°çš„ PDEï¼‰
    
    æ ¸å¿ƒæŒ‘æˆ˜ï¼š
    - æ ·æœ¬ç»Ÿè®¡ï¼ˆå‡å€¼ã€æ–¹å·®ã€pdfï¼‰
    - Monte Carlo æ–¹æ³•
    - éšæœº Galerkin
    - ä¸ç¡®å®šæ€§é‡åŒ–
    """
    
    def get_pde_type(self) -> str:
        return 'stochastic'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        SPDE å‚æ•°æ¨èï¼š
        - éœ€è¦å¤šæ¬¡å®ç°ï¼ˆMCæ ·æœ¬æ•°ï¼‰
        - æˆ–ä½¿ç”¨ Polynomial Chaos
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 64,
                'degree': 2,
                'n_samples': 100  # Monte Carlo æ ·æœ¬æ•°
            }
        elif mode == 'fix_time':
            return {
                'resolution': 32,
                'degree': 1,
                'n_samples': 50
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—éšæœºPDEä¸“ç”¨æŒ‡æ ‡ï¼š
        - mean_solution: è§£çš„å‡å€¼
        - variance: è§£çš„æ–¹å·®
        - confidence_interval: ç½®ä¿¡åŒºé—´
        - mc_convergence_rate: MC æ”¶æ•›ç‡ï¼ˆ1/âˆšNï¼‰
        - moments_accuracy: é«˜é˜¶çŸ©ç²¾åº¦
        """
        metrics = {}
        
        try:
            # è¯»å–å¤šä¸ªæ ·æœ¬ï¼ˆå‡è®¾å­˜å‚¨ä¸º u_sample_0.npy, u_sample_1.npy, ...ï¼‰
            samples = []
            i = 0
            while True:
                sample_file = self.agent_output_dir / f'u_sample_{i}.npy'
                if not sample_file.exists():
                    break
                u_sample = np.load(sample_file)
                samples.append(u_sample)
                i += 1
            
            if len(samples) > 0:
                samples = np.array(samples)  # shape: (n_samples, ...)
                
                # 1. å‡å€¼å’Œæ–¹å·®
                u_mean = np.mean(samples, axis=0)
                u_var = np.var(samples, axis=0)
                
                metrics['n_samples'] = len(samples)
                metrics['mean_L2_norm'] = float(np.linalg.norm(u_mean))
                metrics['mean_variance'] = float(np.mean(u_var))
                metrics['max_variance'] = float(np.max(u_var))
                
                # 2. ç½®ä¿¡åŒºé—´å®½åº¦ï¼ˆ95% CIï¼‰
                u_std = np.std(samples, axis=0)
                ci_width = 1.96 * u_std / np.sqrt(len(samples))
                metrics['mean_ci_width'] = float(np.mean(ci_width))
                
                # 3. ä¸ oracle å‡å€¼æ¯”è¾ƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                oracle_mean_file = self.oracle_output_dir / 'u_mean.npy'
                if oracle_mean_file.exists():
                    u_mean_oracle = np.load(oracle_mean_file)
                    mean_error = np.linalg.norm(u_mean - u_mean_oracle) / np.linalg.norm(u_mean_oracle)
                    metrics['mean_solution_error'] = float(mean_error)
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics


class MultiphysicsCaseTest(BaseCaseTest):
    """
    å¤šç‰©ç†è€¦åˆæµ‹è¯•ï¼ˆæµå›ºè€¦åˆã€çƒ­-åŠ›è€¦åˆã€ç”µç£-çƒ­è€¦åˆç­‰ï¼‰
    
    æ ¸å¿ƒæŒ‘æˆ˜ï¼š
    - å¤šåœºè€¦åˆ
    - å—é¢„æ¡ä»¶
    - æ—¶é—´å°ºåº¦åˆ†ç¦»
    - ç•Œé¢æ¡ä»¶
    """
    
    def get_pde_type(self) -> str:
        return 'multiphysics'
    
    def _get_test_params(self, mode: str) -> Dict[str, Any]:
        """
        å¤šç‰©ç†å‚æ•°æ¨èï¼š
        - åˆ†åŒº/å•åŸŸæ–¹æ³•
        - å—é¢„æ¡ä»¶å™¨
        - å¯èƒ½éœ€è¦ä¸åŒç½‘æ ¼
        """
        if mode == 'fix_accuracy':
            return {
                'resolution': 64,
                'degree': 2,
                'dt': 0.001
            }
        elif mode == 'fix_time':
            return {
                'resolution': 32,
                'degree': 1,
                'dt': 0.01
            }
        else:
            raise ValueError(f"Unknown mode: {mode}")
    
    def _compute_specialized_metrics(self, result: Dict) -> Dict:
        """
        è®¡ç®—å¤šç‰©ç†è€¦åˆä¸“ç”¨æŒ‡æ ‡ï¼š
        - coupling_iterations: è€¦åˆè¿­ä»£æ¬¡æ•°
        - field_conservation: å„åœºå®ˆæ’æ€§
        - interface_continuity: ç•Œé¢è¿ç»­æ€§
        - load_balance: è´Ÿè½½å¹³è¡¡ï¼ˆä¸åŒç‰©ç†åœºï¼‰
        """
        metrics = {}
        
        try:
            # è¯»å–å¤šä¸ªåœº
            fields = ['u', 'p', 'T', 'rho']  # å¯èƒ½çš„åœºå˜é‡
            available_fields = []
            
            for field_name in fields:
                field_file = self.agent_output_dir / f'{field_name}.npy'
                if field_file.exists():
                    available_fields.append(field_name)
            
            metrics['available_fields'] = available_fields
            metrics['n_fields'] = len(available_fields)
            
            # è¯»å–è€¦åˆè¿­ä»£ä¿¡æ¯
            meta_file = self.agent_output_dir / 'meta.json'
            if meta_file.exists():
                with open(meta_file) as f:
                    meta = json.load(f)
                
                if 'coupling_iterations' in meta:
                    iters = meta['coupling_iterations']
                    if isinstance(iters, list):
                        metrics['coupling_iterations_mean'] = float(np.mean(iters))
                        metrics['coupling_iterations_max'] = int(np.max(iters))
                    else:
                        metrics['coupling_iterations'] = iters
            
            # æ£€æŸ¥ç•Œé¢è¿ç»­æ€§ï¼ˆå¦‚æœæœ‰ç•Œé¢æ•°æ®ï¼‰
            interface_file = self.agent_output_dir / 'interface_jump.npy'
            if interface_file.exists():
                jump = np.load(interface_file)
                metrics['interface_jump_L2'] = float(np.linalg.norm(jump))
                metrics['interface_jump_max'] = float(np.max(np.abs(jump)))
            
            # è¯»å–æ±‚è§£å™¨ä¿¡æ¯
            solver_info = self._read_solver_info()
            if solver_info:
                metrics.update(solver_info)
            
        except Exception as e:
            metrics['error'] = f"Failed to compute specialized metrics: {str(e)}"
        
        return metrics
